{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 1 - Prompt Engineering for LLMs Exercises\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/dair-ai/maven-pe-for-llms-9/blob/main/exercises/session-1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# update or install the necessary libraries\n",
    "!pip install --upgrade openai\n",
    "!pip install --upgrade python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the libraries\n",
    "import openai\n",
    "import os\n",
    "import IPython\n",
    "from langchain.llms import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import textwrap\n",
    "\n",
    "# load the environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# API configuration\n",
    "openai.api_key = os.getenv(\"API_KEY\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using The Chat LLM (GPT-3.5-Turbo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(messages, model=\"gpt-3.5-turbo\", temperature=0, max_tokens=300):\n",
    "    response = openai.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Getting Started"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the prompt below using different temperature values. Try with high and low temperature values, including a temperature value of `0`. Do you see any differences in the outputs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt engineering is the process of designing and creating prompts that are used in various contexts, such as in user\n",
      "interfaces, surveys, questionnaires, and interactive systems. The goal of prompt engineering is to create clear,\n",
      "concise, and effective prompts that help guide users and elicit the desired responses or actions. This can involve\n",
      "considering factors such as language, tone, formatting, and placement of prompts to optimize user experience and\n",
      "engagement. Prompt engineering is often used in fields such as human-computer interaction, psychology, marketing, and\n",
      "education.\n"
     ]
    }
   ],
   "source": [
    "user_message = \"What is prompt engineering?\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": user_message\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(messages, temperature=0.2)\n",
    "response = textwrap.wrap(response, 120)\n",
    "print('\\n'.join(response))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer: \n",
    "\n",
    "By setting temperature to zero, the output got very conservative (not mentioning LLM domain whatsoever), although it avoided any kind of hallucination. On the other hand, setting a large value of the temperature (e.g., 1.5), the output still seems to fail finding the right context and generalizes too much across a wide range of possible scenarios. Here, it would be recommended to add in the user message the correct context, for instance in prompt engineering for NLP applications. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Text Summarization\n",
    "\n",
    "Modify the prompt below to use 3 short sentences and an exciting tone. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get ready to kick those pesky bacterial infections to the curb with antibiotics! These powerful medications either wipe\n",
      "out the bacteria or stop them from multiplying, giving your immune system the upper hand in the fight. Just remember,\n",
      "antibiotics won't work on viruses, so use them wisely to avoid building up resistance.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Your task is to summarize an abstract into three sentences and use a more exciting tone. \n",
    "\n",
    "Abstract: Antibiotics are a type of medication used to treat bacterial infections. They work by either killing the bacteria or preventing them from reproducing, \n",
    "allowing the body's immune system to fight off the infection. Antibiotics are usually taken orally in the form of pills, capsules, or liquid solutions, or \n",
    "sometimes administered intravenously. They are not effective against viral infections, and using them inappropriately can lead to antibiotic resistance.\n",
    "\"\"\"\n",
    "\n",
    "message = [\n",
    "    {   \n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(message, temperature=0.)\n",
    "response = textwrap.wrap(response, 120)\n",
    "print('\\n'.join(response))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Explain Like I am 5\n",
    "\n",
    "Modify the prompt below to instruct the model to explain the paragraph in one sentence like \"I am 5\". Do you observe any differences in language style?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antibiotics are special medicines that help your body fight off bad germs that make you sick, but they only work on\n",
      "certain kinds of germs and you have to take them exactly how the doctor says so they can keep working.\n"
     ]
    }
   ],
   "source": [
    "user_message = \"\"\"\n",
    "Antibiotics are a type of medication used to treat bacterial infections. They work by either killing the bacteria or preventing them from reproducing, \n",
    "allowing the body's immune system to fight off the infection. Antibiotics are usually taken orally in the form of pills, capsules, \n",
    "or liquid solutions, or sometimes administered intravenously. They are not effective against viral infections, and using them inappropriately can lead to antibiotic resistance. \n",
    "\n",
    "Explain the above in one sentence like I am 5:\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": user_message\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(messages)\n",
    "response = textwrap.wrap(response, 120)\n",
    "print('\\n'.join(response))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer: \n",
    "\n",
    "In general, the output is written with very simple vocabulary that a child can understand the meanining quite easily."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Unsure About Answer\n",
    "\n",
    "Modify the prompt below to elicit the model to respond that it isn't sure about the answer. Hint: you can try to remove important details from the prompt. The goal is to ensure that the model doesn't make up an answer if it's not able to find an answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsure about answer\n"
     ]
    }
   ],
   "source": [
    "user_message = \"\"\"\n",
    "Answer the question based on the context below. Keep the answer short and concise. Respond \"Unsure about answer\" if not sure about the answer.\n",
    "\n",
    "Context: Teplizumab traces its roots to a New Jersey drug company called Ortho Pharmaceutical. There, scientists generated an early version of the antibody, dubbed OKT3. \n",
    "In 1986, it was approved to help prevent organ rejection after kidney transplants, making it the first therapeutic antibody allowed for human use.\n",
    "\n",
    "Question: From which animal OKT3 originally sourced from?\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": user_message\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(messages, \n",
    "                          temperature=1.6)\n",
    "response = textwrap.wrap(response, 120)\n",
    "print('\\n'.join(response))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer: \n",
    "\n",
    "By removing the sentence which contains the clear answer and modifying the given question. Additionally the temperature is increased to enhance the randomness of the results. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Explain Answers\n",
    "\n",
    "Modify the prompt below to instruct the model to provide an explanation for the answer selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutral\n",
      "\n",
      "Explanation: The text expresses a neutral sentiment as the speaker is neither overly positive nor negative about the food, simply stating that it was \"okay.\"\n"
     ]
    }
   ],
   "source": [
    "user_message = \"\"\"\n",
    "Classify the text into neutral, negative or positive, and provide an explanation of the output sentiment.\n",
    "\n",
    "Text: I think the food was okay.\n",
    "\n",
    "Sentiment:\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": user_message\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(messages)\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Precise Output and Delimiters\n",
    "Add an additional instruction to use delimiter around the input text. Also, add an instruction to output the label in lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \"I think the food was okay.\"\n",
      "Output: negative\n"
     ]
    }
   ],
   "source": [
    "user_message = \"\"\"\n",
    "Context: Classify the text into neutral, negative or positive. Additionally, use delimiter around the input text and output the label in lowercase.\n",
    "\n",
    "Text: I think the food was okay.\n",
    "\n",
    "Sentiment:\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": user_message\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(messages)\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Information Extraction\n",
    "\n",
    "Use the poem below to create a prompt that instructs the model to extract all the verbs, including the number of verbs found. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peering, stood, wondering, fearing, doubting, dreaming, dared, broke, gave, spoken, whispered, echoed, murmured\n"
     ]
    }
   ],
   "source": [
    "user_message = \"\"\"\n",
    "Extact all the verbs from the context below.\n",
    "\n",
    "Context: Deep into that darkness peering,\n",
    "\n",
    "Long I stood there, wondering, fearing,\n",
    "\n",
    "Doubting, dreaming dreams no mortals\n",
    "\n",
    "Ever dared to dream before;\n",
    "\n",
    "But the silence was unbroken,\n",
    "\n",
    "And the stillness gave no token,\n",
    "\n",
    "And the only word there spoken\n",
    "\n",
    "Was the whispered word, \"Lenore!\"\n",
    "\n",
    "This I whispered, and an echo\n",
    "\n",
    "Murmured back the word, \"Lenore!\"\n",
    "\n",
    "Merely this, and nothing more.\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": user_message\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(messages)\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Keep it Short and Concise | Use Role Playing\n",
    "\n",
    "Modify the prompt below to instruct the model to keep AI responses concise and short. Modify the prompt so that it uses a `system_message` and `user_message`. In addition, modify the prompt so that it encourages further interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black holes are formed when massive stars collapse under their own gravity at the end of their life cycle. This collapse\n",
      "causes the star's core to become extremely dense, creating a gravitational pull so strong that not even light can\n",
      "escape, leading to the formation of a black hole.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"The following is a conversation with an AI research assistant. The assistant tone is should be consice and short.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Hello, who are you?\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"Greetings! I am an AI research assistant. How can I help you today?\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Can you tell me about the creation of black holes?\"\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(messages)\n",
    "response = textwrap.wrap(response, 120)\n",
    "print('\\n'.join(response))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Step-by-Step Solution\n",
    "\n",
    "Modify the prompt to steer the model to think in steps before providing an answer. Try to be specific about the particular steps you need the model to take. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Identify the odd positions and extract the numbers:\n",
      "Odd positions in the group are positions 1, 3, 5, and 7.\n",
      "Numbers at these positions are 4, 9, 12, and 1.\n",
      "\n",
      "Step 2: Calculate the sum of the numbers at odd positions:\n",
      "4 + 9 + 12 + 1 = 26\n",
      "\n",
      "Step 3: Determine if the sum is an even number:\n",
      "Since 26 is divisible by 2 without a remainder, it is an even number.\n",
      "\n",
      "Therefore, the sum of the numbers in odd positions (4, 9, 12, 1) in the given group (4, 8, 9, 15, 12, 2, 1) is an even number (26).\n"
     ]
    }
   ],
   "source": [
    "user_message = \"\"\"\n",
    "The numbers in the following group in odd positions will add up to an even number: 4, 8, 9, 15, 12, 2, 1.\n",
    "Solve by breaking the problem into steps. \n",
    "First, identify the odd positions and extract these numbers. Second, show that the result of the sum is an even number.\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": user_message\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(messages)\n",
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
